{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JamUNet model trained with the spatial dataset - training and validation\n",
    "\n",
    "This notebook was used for training and validating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\piete\\OneDrive\\Documenten\\DSAIE MORPH\\jamunet-morpho-braided\n"
     ]
    }
   ],
   "source": [
    "# # move to root directory\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload modules to avoid restarting the notebook every time these are updated\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules \n",
    "\n",
    "import torch\n",
    "import joblib\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from model.train_eval import * \n",
    "from preprocessing.dataset_generation import create_full_dataset\n",
    "from preprocessing.dataset_generation import combine_datasets\n",
    "from postprocessing.save_results import *\n",
    "from postprocessing.plot_results import *\n",
    "\n",
    "# enable interactive widgets in Jupyter Notebook\n",
    "%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Device Count:  1\n",
      "CUDA Device Name:  NVIDIA GeForce RTX 3070\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# set the device where operations are performed\n",
    "# if only one GPU is present you might need to remove the index \"0\" \n",
    "# torch.device('cuda:0') --> torch.device('cuda') / torch.cuda.get_device_name(0) --> torch.cuda.get_device_name() \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(\"CUDA Device Count: \", torch.cuda.device_count())\n",
    "    print(\"CUDA Device Name: \", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logical CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "num_cpus = os.cpu_count()  # total logical cores\n",
    "print(\"Logical CPU cores:\", num_cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set common keys required for functions\n",
    "\n",
    "train = 'training'\n",
    "val = 'validation'\n",
    "test = 'testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\piete\\OneDrive\\Documenten\\DSAIE MORPH\\jamunet-morpho-braided\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\piete\\OneDrive\\Documenten\\DSAIE MORPH\\jamunet-morpho-braided\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os\n",
    "print(\"Working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# from natsort import natsorted\n",
    "# from osgeo import gdal\n",
    "\n",
    "# def merge_yearly_to_npy(base_dir, collection='JRC_GSW1_4_MonthlyHistory'):\n",
    "#     \"\"\"\n",
    "#     Merge all monthly .tif/.npy files of each year into a single .npy file per year.\n",
    "#     Keeps original folder structure.\n",
    "\n",
    "#     base_dir: root folder of preprocessed_PIETER\n",
    "#     collection: substring to match collection folders (e.g. 'JRC_GSW1_4_MonthlyHistory')\n",
    "#     \"\"\"\n",
    "#     # loop over subfolders in base_dir\n",
    "#     for folder_name in os.listdir(base_dir):\n",
    "#         if collection in folder_name:\n",
    "#             folder_path = os.path.join(base_dir, folder_name)\n",
    "#             if not os.path.isdir(folder_path):\n",
    "#                 continue\n",
    "            \n",
    "#             # collect all tif/npy files (you currently only have .tif)\n",
    "#             all_files = [\n",
    "#                 f for f in os.listdir(folder_path)\n",
    "#                 if f.endswith('.tif') or f.endswith('.npy')\n",
    "#             ]\n",
    "#             all_files = natsorted(all_files)  # sort by date in filenames\n",
    "\n",
    "#             if not all_files:\n",
    "#                 print(f\"No tif/npy files found in {folder_path}\")\n",
    "#                 continue\n",
    "\n",
    "#             # group by year (first 4 characters of filename, e.g. '1987_12_01.tif')\n",
    "#             files_by_year = {}\n",
    "#             for f in all_files:\n",
    "#                 year = f[:4]\n",
    "#                 if not year.isdigit():\n",
    "#                     print(f\"Skipping file with unexpected name: {f}\")\n",
    "#                     continue\n",
    "#                 if year not in files_by_year:\n",
    "#                     files_by_year[year] = []\n",
    "#                 files_by_year[year].append(os.path.join(folder_path, f))\n",
    "            \n",
    "#             # merge each year\n",
    "#             for year, files in files_by_year.items():\n",
    "#                 year_arrays = []\n",
    "#                 for fpath in files:\n",
    "#                     if fpath.endswith('.npy'):\n",
    "#                         arr = np.load(fpath)\n",
    "#                     elif fpath.endswith('.tif'):\n",
    "#                         ds = gdal.Open(fpath)\n",
    "#                         if ds is None:\n",
    "#                             print(f\"Could not open {fpath} with GDAL, skipping.\")\n",
    "#                             continue\n",
    "#                         arr = ds.ReadAsArray().astype(np.float32)\n",
    "#                         ds = None\n",
    "#                     else:\n",
    "#                         continue\n",
    "\n",
    "#                     year_arrays.append(arr)\n",
    "\n",
    "#                 # optional: sanity check that all arrays have the same shape\n",
    "#                 shapes = {a.shape for a in year_arrays}\n",
    "#                 if len(shapes) > 1:\n",
    "#                     print(f\"WARNING: Different shapes for year {year} in {folder_path}: {shapes}\")\n",
    "#                     # you can decide to continue or skip; here I skip:\n",
    "#                     continue\n",
    "\n",
    "#                 if len(year_arrays) != 12:\n",
    "#                     print(f\"Skipping {year} in {folder_path}, only {len(year_arrays)} files (expected 12)\")\n",
    "#                     continue\n",
    "\n",
    "#                 # stack months along a new axis (0 = months)\n",
    "#                 merged = np.stack(year_arrays, axis=0)  # shape: (12, H, W)\n",
    "\n",
    "#                 # save merged file\n",
    "#                 out_name = os.path.join(folder_path, f'{year}_allmonths.npy')\n",
    "#                 np.save(out_name, merged)\n",
    "#                 print(f'Merged {len(files)} files into {out_name}')\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# merge_yearly_to_npy(r'C:\\Users\\piete\\OneDrive\\Documenten\\DSAIE MORPH\\jamunet-morpho-braided\\data\\satellite\\preprocessed_PIETER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import numpy as np\n",
    "# from osgeo import gdal\n",
    "\n",
    "# def tiff_to_npy(root_dir, scaled_classes=True):\n",
    "#     \"\"\"\n",
    "#     Walk through all .tif files under root_dir and create .npy versions\n",
    "#     in the same folders. Keeps folder structure intact.\n",
    "#     \"\"\"\n",
    "#     tif_files = glob.glob(os.path.join(root_dir, \"**\", \"*.tif\"), recursive=True)\n",
    "#     print(f\"Found {len(tif_files)} .tif files\")\n",
    "\n",
    "#     for tif in tif_files:\n",
    "#         npy_path = tif.replace(\".tif\", \".npy\")\n",
    "#         if os.path.exists(npy_path):\n",
    "#             continue  # skip if .npy already exists\n",
    "\n",
    "#         try:\n",
    "#             ds = gdal.Open(tif)\n",
    "#             arr = ds.ReadAsArray().astype(np.float32)\n",
    "\n",
    "#             if scaled_classes:\n",
    "#                 arr = arr.astype(np.int32)\n",
    "#                 arr[arr == 0] = -1\n",
    "#                 arr[arr == 1] = 0\n",
    "#                 arr[arr == 2] = 1\n",
    "\n",
    "#             np.save(npy_path, arr)\n",
    "#             print(f\"Saved {npy_path}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to process {tif}: {e}\")\n",
    "\n",
    "# # Usage\n",
    "# dataset_path = r\"data\\satellite\\preprocessed_PIETER\"\n",
    "# tiff_to_npy(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# class LazyDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     Lazily load YEARLY .npy satellite images.\n",
    "\n",
    "#     Assumes:\n",
    "#       - combine_datasets(...) returns:\n",
    "#           inputs: list of lists of yearly .npy paths\n",
    "#           targets: list of single yearly .npy paths\n",
    "#       - each yearly .npy has all 12 months (e.g. shape (12, H, W) or (12, C, H, W))\n",
    "\n",
    "#     For each sample:\n",
    "#       x = stack of (year_target - 1) yearly arrays  -> shape (T, ...)\n",
    "#       y = 3rd month (index 2) of the target year    -> shape (...)\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         train_val_test,\n",
    "#         dir_folders=r\"data\\satellite\\preprocessed_PIETER\",\n",
    "#         year_target=5,\n",
    "#         scaled_classes=True,\n",
    "#         dtype=torch.float32,\n",
    "#     ):\n",
    "#         self.train_val_test = train_val_test\n",
    "#         self.dir_folders = dir_folders\n",
    "#         self.year_target = year_target\n",
    "#         self.scaled_classes = scaled_classes\n",
    "#         self.dtype = dtype\n",
    "#         self.samples = []\n",
    "\n",
    "#         # gather paths only; do NOT load arrays here\n",
    "#         for folder in os.listdir(dir_folders):\n",
    "#             if train_val_test in folder:\n",
    "#                 # folder e.g. \"JRC_GSW1_4_MonthlyHistory_training_r1\"\n",
    "#                 reach_id = folder.split(\"_r\", 1)[1]\n",
    "\n",
    "#                 inputs, targets = combine_datasets(\n",
    "#                     train_val_test,\n",
    "#                     int(reach_id),\n",
    "#                     year_target,\n",
    "#                     dir_folders=dir_folders,\n",
    "#                     scaled_classes=scaled_classes,\n",
    "#                 )\n",
    "\n",
    "#                 for inp_paths, tgt_path in zip(inputs, targets):\n",
    "#                     # inp_paths: list of yearly .npy paths\n",
    "#                     # tgt_path:  single yearly .npy path\n",
    "#                     self.samples.append((inp_paths, tgt_path))\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         inp_paths, tgt_path = self.samples[idx]\n",
    "\n",
    "#         # --- load input sequence (year_target - 1 yearly .npy files) ---\n",
    "#         xs = [np.load(p, mmap_mode=\"r\") for p in inp_paths]  # each: (12, H, W)\n",
    "#         x_np = np.stack(xs, axis=0)  # (T, 12, H, W)\n",
    "\n",
    "#         # flatten (T, 12) -> (T*12) along channels\n",
    "#         if x_np.ndim != 4:\n",
    "#             raise ValueError(f\"Expected input shape (T, 12, H, W), got {x_np.shape}\")\n",
    "#         T, M, H, W = x_np.shape\n",
    "#         x_np = x_np.reshape(T * M, H, W)  # (C, H, W) where C = T*12\n",
    "\n",
    "#         # --- load target year and take ONLY month 3 ---\n",
    "#         year_np = np.load(tgt_path, mmap_mode=\"r\")  # (12, H, W)\n",
    "#         y_np = year_np[2]  # 3rd month\n",
    "\n",
    "#         x = torch.from_numpy(x_np).to(self.dtype)  # (C, H, W)\n",
    "#         y = torch.from_numpy(y_np).to(self.dtype)  # (H, W) or (C', H, W) depending on saved format\n",
    "\n",
    "#         return x, y\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class LazyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        - stacked yearly .npy images (flattened months)\n",
    "    Target:\n",
    "        - always from .tiff files inside:\n",
    "            data/satellite/preprocessed/<reach_folder>/\n",
    "\n",
    "        Target is the 3rd tiff of the year (index 2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_val_test,\n",
    "        dir_folders=r\"data\\satellite\\preprocessed_PIETER\",\n",
    "        target_root=r\"data\\satellite\\dataset_month3\",\n",
    "        year_target=5,\n",
    "        scaled_classes=True,\n",
    "        dtype=torch.float32,\n",
    "    ):\n",
    "        self.train_val_test = train_val_test\n",
    "        self.dir_folders = dir_folders\n",
    "        self.target_root = target_root\n",
    "        self.year_target = year_target\n",
    "        self.scaled_classes = scaled_classes\n",
    "        self.dtype = dtype\n",
    "        self.samples = []\n",
    "\n",
    "        for folder in os.listdir(dir_folders):\n",
    "            if train_val_test in folder:\n",
    "                reach_folder = folder\n",
    "                reach_id = folder.split(\"_r\", 1)[1]\n",
    "\n",
    "                inputs, targets = combine_datasets(\n",
    "                    train_val_test,\n",
    "                    int(reach_id),\n",
    "                    year_target,\n",
    "                    dir_folders=dir_folders,\n",
    "                    scaled_classes=scaled_classes,\n",
    "                )\n",
    "\n",
    "                for inp_paths, tgt_npy_path in zip(inputs, targets):\n",
    "                    tiff_path = self._build_tiff_path_from_npy(\n",
    "                        tgt_npy_path, reach_folder\n",
    "                    )\n",
    "                    self.samples.append((inp_paths, tiff_path))\n",
    "\n",
    "    def _extract_year_from_path(self, path: str) -> str:\n",
    "        base = os.path.basename(path)\n",
    "        m = re.search(r\"\\d{4}\", base)\n",
    "        if m is None:\n",
    "            raise ValueError(f\"Could not extract year from: {base}\")\n",
    "        return m.group(0)\n",
    "\n",
    "    def _build_tiff_path_from_npy(self, tgt_npy_path: str, reach_folder: str) -> str:\n",
    "        year = self._extract_year_from_path(tgt_npy_path)\n",
    "        tiff_dir = os.path.join(self.target_root, reach_folder)\n",
    "\n",
    "        if not os.path.isdir(tiff_dir):\n",
    "            raise FileNotFoundError(f\"Target directory not found: {tiff_dir}\")\n",
    "\n",
    "        tiff_paths = sorted(\n",
    "            glob.glob(os.path.join(tiff_dir, f\"{year}_*.tif\"))\n",
    "            + glob.glob(os.path.join(tiff_dir, f\"{year}_*.tiff\"))\n",
    "        )\n",
    "\n",
    "        if len(tiff_paths) == 0:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No tiffs found for year {year} in {tiff_dir}\"\n",
    "            )\n",
    "        if len(tiff_paths) > 1:\n",
    "            raise ValueError(\n",
    "                f\"Expected 1 tiff for year {year} in {tiff_dir}, \"\n",
    "                f\"found {len(tiff_paths)}: {tiff_paths}\"\n",
    "            )\n",
    "\n",
    "        # single TIFF per year (already month 3)\n",
    "        return tiff_paths[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp_paths, tiff_path = self.samples[idx]\n",
    "\n",
    "        # ---------- INPUT FROM .NPY ----------\n",
    "        xs = [np.load(p, mmap_mode=\"r\") for p in inp_paths]   # each: (12, H, W)\n",
    "        x_np = np.stack(xs, axis=0)                           # (T, 12, H, W)\n",
    "\n",
    "        if x_np.ndim != 4:\n",
    "            raise ValueError(f\"Expected (T,12,H,W), got {x_np.shape}\")\n",
    "\n",
    "        T, M, H, W = x_np.shape\n",
    "        x_np = x_np.reshape(T * M, H, W)                      # (C, H, W)\n",
    "\n",
    "        # ---------- TARGET FROM .TIFF (PIL) ----------\n",
    "        if not os.path.exists(tiff_path):\n",
    "            raise FileNotFoundError(f\"Missing TIFF: {tiff_path}\")\n",
    "\n",
    "        with Image.open(tiff_path) as img:\n",
    "            y_np = np.array(img)\n",
    "\n",
    "        # if multi-band, reduce to one channel\n",
    "        if y_np.ndim == 3:\n",
    "            y_np = y_np[:, :, 0]\n",
    "\n",
    "        x = torch.from_numpy(x_np).to(self.dtype)\n",
    "\n",
    "\n",
    "        label = torch.from_numpy(y_np).long()\n",
    "        valid_mask = (label != 0).float()       \n",
    "        y_bin = (label == 2).long() \n",
    "\n",
    "        return x, y_bin, valid_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020 NPY files found\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1988_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1989_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1990_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1991_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1992_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1993_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1994_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1995_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1996_allmonths.npy\n",
      "data/satellite/preprocessed_PIETER\\JRC_GSW1_4_MonthlyHistory_testing_r1\\1997_allmonths.npy\n"
     ]
    }
   ],
   "source": [
    "# load all datasets\n",
    "\n",
    "# by default March images are used - if another month is used change the number (available months: 1-4)\n",
    "dataset_path = r'data\\satellite\\preprocessed_PIETER'\n",
    "\n",
    "dtype=torch.float32\n",
    "\n",
    "\n",
    "\n",
    "train_set = LazyDataset('training', dir_folders=dataset_path, dtype=dtype)\n",
    "val_set   = LazyDataset('validation', dir_folders=dataset_path, dtype=dtype)\n",
    "test_set  = LazyDataset('testing', dir_folders=dataset_path, dtype=dtype)\n",
    "\n",
    "# now you can safely check .npy files\n",
    "import glob\n",
    "files = glob.glob(\"data/satellite/preprocessed_PIETER/**/*.npy\", recursive=True)\n",
    "print(len(files), \"NPY files found\")\n",
    "for f in files[:10]:\n",
    "    print(f)\n",
    "\n",
    "\n",
    "\n",
    "# train_set = create_full_dataset(train, dir_folders=dataset_path, device=device, dtype=dtype)\n",
    "# val_set = create_full_dataset(val, dir_folders=dataset_path, device=device, dtype=dtype)\n",
    "# test_set = create_full_dataset(test, dir_folders=dataset_path, device=device, dtype=dtype)\n",
    "\n",
    "\n",
    "\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from functools import partial\n",
    "\n",
    "# build = partial(create_full_dataset, dir_folders=dataset_path, device=device, dtype=dtype)\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers=16) as ex:\n",
    "#     train_set, val_set, test_set = ex.map(build, [train, val, test])\n",
    "\n",
    "# zonder processpoolexecutor 2.40 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset samples: 840,\n",
      "Validation dataset samples: 30,\n",
      "Testing dataset samples: 30\n"
     ]
    }
   ],
   "source": [
    "print(f'Training dataset samples: {len(train_set)},\\n\\\n",
    "Validation dataset samples: {len(val_set)},\\n\\\n",
    "Testing dataset samples: {len(test_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Attention!</span>** \n",
    "\\\n",
    "Uncomment the next cells if larger training, validation, and testing datasets are needed. These cells load all months datasets (January, February, March, and April) and then merge them into one dataset. \n",
    "\\\n",
    "Keep in mind that due to memory constraints, it is likely that not all four datasets can be loaded. \n",
    "\\\n",
    "Make sure to load the training, validation, and testing datasets in different cells to reduce memory issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_jan = r'data\\satellite\\dataset_month1'\n",
    "# dataset_feb = r'data\\satellite\\dataset_month2'\n",
    "# dataset_mar = r'data\\satellite\\dataset_month3'\n",
    "# dataset_apr = r'data\\satellite\\dataset_month4'\n",
    "\n",
    "# dtype=torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_train_jan, targets_train_jan = create_full_dataset(train, dir_folders=dataset_jan, device=device, dtype=dtype).tensors\n",
    "# inputs_train_feb, targets_train_feb = create_full_dataset(train, dir_folders=dataset_feb, device=device, dtype=dtype).tensors\n",
    "# inputs_train_mar, targets_train_mar = create_full_dataset(train, dir_folders=dataset_mar, device=device, dtype=dtype).tensors\n",
    "# inputs_train_apr, targets_train_apr = create_full_dataset(train, dir_folders=dataset_apr, device=device, dtype=dtype).tensors\n",
    "\n",
    "# inputs_train = torch.cat((inputs_train_jan, inputs_train_feb, inputs_train_mar, inputs_train_apr))\n",
    "# targets_train = torch.cat((targets_train_jan, targets_train_feb, targets_train_mar, targets_train_apr))\n",
    "# train_set = TensorDataset(inputs_train, targets_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_val_jan, targets_val_jan = create_full_dataset(val, dir_folders=dataset_jan, device=device, dtype=dtype).tensors\n",
    "# inputs_val_feb, targets_val_feb = create_full_dataset(val, dir_folders=dataset_feb, device=device, dtype=dtype).tensors\n",
    "# inputs_val_mar, targets_val_mar = create_full_dataset(val, dir_folders=dataset_mar, device=device, dtype=dtype).tensors\n",
    "# inputs_val_apr, targets_val_apr = create_full_dataset(val, dir_folders=dataset_apr, device=device, dtype=dtype).tensors\n",
    "\n",
    "# inputs_val = torch.cat((inputs_val_jan, inputs_val_feb, inputs_val_mar, inputs_val_apr))\n",
    "# targets_val = torch.cat((targets_val_jan, targets_val_feb, targets_val_mar, targets_val_apr))\n",
    "# val_set = TensorDataset(inputs_val, targets_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_test_jan, targets_test_jan = create_full_dataset(test, dir_folders=dataset_jan, device=device, dtype=dtype).tensors\n",
    "# inputs_test_feb, targets_test_feb = create_full_dataset(test, dir_folders=dataset_feb, device=device, dtype=dtype).tensors\n",
    "# inputs_test_mar, targets_test_mar = create_full_dataset(test, dir_folders=dataset_mar, device=device, dtype=dtype).tensors\n",
    "# inputs_test_apr, targets_test_apr = create_full_dataset(test, dir_folders=dataset_apr, device=device, dtype=dtype).tensors\n",
    "\n",
    "# inputs_test = torch.cat((inputs_test_jan, inputs_test_feb, inputs_test_mar, inputs_test_apr))\n",
    "# targets_test = torch.cat((targets_test_jan, targets_test_feb, targets_test_mar, targets_test_apr))\n",
    "# test_set = TensorDataset(inputs_test, targets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Attention!</span>** \n",
    "\\\n",
    "It is not needed to scale and normalize the dataset as the pixel values are already $[0, 1]$.\n",
    "\\\n",
    "If scaling and normalization are performed anyways, then **the model inputs have to be changed** as the normalized datasets are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs and targets using the training dataset\n",
    "\n",
    "# scaler_x, scaler_y = scaler(train_set)\n",
    "\n",
    "# normalized_train_set = normalize_dataset(train_set, scaler_x, scaler_y)\n",
    "# normalized_val_set = normalize_dataset(val_set, scaler_x, scaler_y)\n",
    "# normalized_test_set = normalize_dataset(test_set, scaler_x, scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers to be loaded in seperate notebooks (i.e., for testing the model)\n",
    "# should not change unless seed is changed or augmentation increased (randomsplit changes)\n",
    "\n",
    "# joblib.dump(scaler_x, r'model\\scalers\\scaler_x.joblib')\n",
    "# joblib.dump(scaler_y, r'model\\scalers\\scaler_y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JamUNet architecture\n",
    "\n",
    "from model.st_unet.st_unet import *\n",
    "\n",
    "# n_channels = train_set[0][0].shape[0]\n",
    "n_channels = 48\n",
    "n_classes = 2\n",
    "init_hid_dim = 8\n",
    "kernel_size = 3\n",
    "pooling = 'max'\n",
    "\n",
    "model = UNet3D(n_channels=n_channels, n_classes=n_classes, init_hid_dim=init_hid_dim, \n",
    "               kernel_size=kernel_size, pooling=pooling, bilinear=False, drop_channels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(48, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv3d): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3d): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3d): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3d): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_conv): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "  (down4): Down(\n",
       "    (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3d): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv3d): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print model architecture\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 5.26e+05\n",
      "Model size: 2.01 MB\n"
     ]
    }
   ],
   "source": [
    "# print total number of parameters and model size\n",
    "\n",
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {num_parameters:.2e}\")\n",
    "model_size_MB = num_parameters * 4 / (1024 ** 2)  # assuming float32 precision\n",
    "print(f\"Model size: {model_size_MB:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Attention!</span>** \n",
    "\\\n",
    "Since it is not needed to scale and normalize the dataset (see above), the input for the Data Loader are not the normalized datasets.\n",
    "\\\n",
    "If normalization is performed, the normalized datasets become the inputs to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make it faster\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 0.05\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "water_threshold = 0.5\n",
    "physics = False    # no physics-induced loss terms in the training loss if False\n",
    "alpha_er = 1e-4    # needed only if physics=True\n",
    "alpha_dep = 1e-4   # needed only if physics=True\n",
    "\n",
    "# optimizer to train the model with backpropagation\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler for decreasing the learning rate \n",
    "# every tot epochs (step_size) with given factor (gamma)\n",
    "step_size = 15     # set to None to remove the scheduler\n",
    "gamma = 0.75       # set to None to remove the scheduler\n",
    "if (step_size and gamma) is not None:\n",
    "    scheduler = StepLR(optimizer, step_size = step_size, gamma = gamma)\n",
    "\n",
    "# dataloaders to input data to the model in batches -- see note above if normalization is performed\n",
    "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True) \n",
    "# val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, prefetch_factor=0)\n",
    "# val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, prefetch_factor=0)\n",
    "# test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True, prefetch_factor=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training loss: 1.58e-01, Validation loss: 1.23e-01, Best validation loss: 1.23e-01  | Metrics: Accuracy: 0.953, Precision: 0.659, Recall: 0.750, F1-score: 0.701, CSI-score: 0.542, Best recall: 0.750\n",
      "Current learning rate: 0.05\n",
      "Epoch: 2 | Training loss: 1.06e-01, Validation loss: 1.04e-01, Best validation loss: 1.04e-01  | Metrics: Accuracy: 0.958, Precision: 0.721, Recall: 0.722, F1-score: 0.717, CSI-score: 0.561, Best recall: 0.750\n",
      "Current learning rate: 0.05\n",
      "Epoch: 3 | Training loss: 9.85e-02, Validation loss: 1.08e-01, Best validation loss: 1.04e-01  | Metrics: Accuracy: 0.957, Precision: 0.692, Recall: 0.785, F1-score: 0.734, CSI-score: 0.581, Best recall: 0.785\n",
      "Current learning rate: 0.037500000000000006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update the learning rate\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# model training\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwater_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphysics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphysics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_er\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_er\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                           \u001b[49m\u001b[43malpha_dep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_dep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_er_dep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_er_dep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# model validation\u001b[39;00m\n\u001b[0;32m     60\u001b[0m val_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_csi_score \u001b[38;5;241m=\u001b[39m validation_unet(model, val_loader, \n\u001b[0;32m     61\u001b[0m                                                                                                  device\u001b[38;5;241m=\u001b[39mdevice, loss_f\u001b[38;5;241m=\u001b[39mloss_f, \n\u001b[0;32m     62\u001b[0m                                                                                                  water_threshold\u001b[38;5;241m=\u001b[39mwater_threshold)\n",
      "File \u001b[1;32mc:\\Users\\piete\\OneDrive\\Documenten\\DSAIE MORPH\\jamunet-morpho-braided\\model\\train_eval.py:91\u001b[0m, in \u001b[0;36mtraining_unet\u001b[1;34m(model, loader, optimizer, nonwater, water, pixel_size, water_threshold, device, loss_f, physics, alpha_er, alpha_dep, loss_er_dep)\u001b[0m\n\u001b[0;32m     87\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     89\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     92\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     93\u001b[0m     y_bin \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# already {0,1}\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piete\\miniconda3\\envs\\MORPH_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\piete\\miniconda3\\envs\\MORPH_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:759\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    757\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m--> 759\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\piete\\miniconda3\\envs\\MORPH_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:98\u001b[0m, in \u001b[0;36mpin_memory\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     96\u001b[0m     clone \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[1;32m---> 98\u001b[0m         clone[i] \u001b[38;5;241m=\u001b[39m \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)([pin_memory(sample, device) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data])  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\piete\\miniconda3\\envs\\MORPH_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:64\u001b[0m, in \u001b[0;36mpin_memory\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpin_memory\u001b[39m(data, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize training, validation losses and metrics\n",
    "train_losses, val_losses = [], []\n",
    "accuracies, precisions, recalls, f1_scores, csi_scores = [], [], [], [], []\n",
    "\n",
    "# set classification loss - possible options: 'BCE', 'BCE_Logits', and 'Focal'\n",
    "\n",
    "\n",
    "\n",
    "loss_f = 'BCE'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# set regression loss for physics-induced terms\n",
    "# possible options: 'Huber', 'RMSE', and 'MAE'\n",
    "loss_er_dep = 'Huber'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# IGNORE_LABEL = 255  # value to ignore in the loss\n",
    "\n",
    "# def remap_labels(mask, nodata_value=-1, nonwater_value=0):\n",
    "#     \"\"\"\n",
    "#     mask: (N, H, W) or (H, W) with original labels\n",
    "#     returns: same shape, values in {0, 1, IGNORE_LABEL}\n",
    "#     \"\"\"\n",
    "#     mask = mask.clone()\n",
    "\n",
    "#     # nodata -> ignore\n",
    "#     mask[mask == nodata_value] = IGNORE_LABEL\n",
    "\n",
    "#     # non-water -> 0\n",
    "#     mask[mask == nonwater_value] = 0\n",
    "\n",
    "#     # everything else -> 1 (water)\n",
    "#     mask[(mask != 0) & (mask != IGNORE_LABEL)] = 1\n",
    "\n",
    "#     return mask.long()\n",
    "\n",
    "# # classification loss: CrossEntropy with ignore_index for nodata\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=IGNORE_LABEL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    # update learning rate\n",
    "    if (step_size and gamma) is not None:\n",
    "        scheduler.step() # update the learning rate\n",
    "    \n",
    "    # model training\n",
    "    train_loss = training_unet(model, train_loader, optimizer, water_threshold=water_threshold, \n",
    "                               device=device, loss_f=loss_f, physics=physics, alpha_er=alpha_er, \n",
    "                               alpha_dep=alpha_dep, loss_er_dep=loss_er_dep)\n",
    "\n",
    "    # model validation\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_csi_score = validation_unet(model, val_loader, \n",
    "                                                                                                     device=device, loss_f=loss_f, \n",
    "                                                                                                     water_threshold=water_threshold)\n",
    "\n",
    "    if epoch == 1:\n",
    "        best_loss = val_loss\n",
    "        best_recall = val_recall\n",
    "    \n",
    "    # save model with min val loss\n",
    "    if val_loss<=best_loss:\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        count = 0\n",
    "    # save model with max recall\n",
    "    if val_recall>=best_recall:\n",
    "        best_model_recall = copy.deepcopy(model)\n",
    "        best_recall = val_recall\n",
    "        best_epoch = epoch\n",
    "        count = 0\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    accuracies.append(val_accuracy)\n",
    "    precisions.append(val_precision)\n",
    "    recalls.append(val_recall)\n",
    "    f1_scores.append(val_f1_score)\n",
    "    csi_scores.append(val_csi_score)\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    if epoch%1 == 0:\n",
    "        print(f\"Epoch: {epoch} | \" +\n",
    "              f\"Training loss: {train_loss:.2e}, Validation loss: {val_loss:.2e}, Best validation loss: {best_loss:.2e} \" + \n",
    "              f\" | Metrics: Accuracy: {val_accuracy:.3f}, Precision: {val_precision:.3f}, Recall: {val_recall:.3f},\\\n",
    " F1-score: {val_f1_score:.3f}, CSI-score: {val_csi_score:.3f}, Best recall: {best_recall:.3f}\")\n",
    "        if (step_size and gamma) is not None:\n",
    "            print(f'Current learning rate: {scheduler.get_last_lr()[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [accuracies, precisions, recalls, f1_scores, csi_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store training and validation losses and metrics to be stored in a .csv file for later postprocessing\n",
    "# always check the dataset month key\n",
    "\n",
    "save_losses_metrics(train_losses, val_losses, metrics, 'spatial', model, 3, init_hid_dim, \n",
    "                    kernel_size, pooling, learning_rate, step_size, gamma, batch_size, num_epochs, \n",
    "                    water_threshold, physics, alpha_er, alpha_dep, dir_output=r'model\\losses_metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Attention!</span>** \n",
    "\\\n",
    "Always remember to rename the <code>save_path</code> file before running the whole notebook to avoid overwrting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with min validation loss\n",
    "# always check the dataset month key\n",
    "\n",
    "save_model_path(best_model, 'spatial', 'loss', 3, init_hid_dim, kernel_size, pooling, learning_rate, \n",
    "                step_size, gamma, batch_size, num_epochs, water_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with max recall\n",
    "# always check the dataset month key\n",
    "\n",
    "save_model_path(best_model_recall, 'spatial', 'recall', 3, init_hid_dim, kernel_size, pooling, learning_rate, \n",
    "                step_size, gamma, batch_size, num_epochs, water_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the min loss model - average loss and metrics\n",
    "\n",
    "model_loss = copy.deepcopy(best_model)\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_csi_score = validation_unet(model_loss, test_loader, device=device, loss_f = loss_f)\n",
    "\n",
    "print(f'Average metrics for test dataset using model with best validation loss:\\n\\n\\\n",
    "{loss_f} loss:          {test_loss:.3e}\\n\\\n",
    "Accuracy:          {test_accuracy:.3f}\\n\\\n",
    "Precision:         {test_precision:.3f}\\n\\\n",
    "Recall:            {test_recall:.3f}\\n\\\n",
    "F1 score:          {test_f1_score:.3f}\\n\\\n",
    "CSI score:         {test_csi_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the max recall model - average loss and metrics\n",
    "\n",
    "model_recall = copy.deepcopy(best_model_recall)\n",
    "test_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_csi_score = validation_unet(model_recall, test_loader, device=device, loss_f = loss_f)\n",
    "\n",
    "print(f'Average metrics for test dataset using model with best validation recall:\\n\\n\\\n",
    "{loss_f} loss:          {test_loss:.3e}\\n\\\n",
    "Accuracy:          {test_accuracy:.3f}\\n\\\n",
    "Precision:         {test_precision:.3f}\\n\\\n",
    "Recall:            {test_recall:.3f}\\n\\\n",
    "F1 score:          {test_f1_score:.3f}\\n\\\n",
    "CSI score:         {test_csi_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses_metrics(train_losses, val_losses, metrics, model_recall, loss_f=loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_evolution(18, test_set, model_loss)\n",
    "\n",
    "device = 'cuda:0'\n",
    "model_loss = model_loss.to(device)\n",
    "\n",
    "img, y, mask = train_set[0]\n",
    "print(torch.unique(y))\n",
    "\n",
    "\n",
    "show_all_images(18, test_set, model_loss, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_evolution(18, test_set, model_recall)\n",
    "show_evolution_nolegend_nn(18, test_set, model_recall, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_evolution(18, val_set, model_recall)\n",
    "show_evolution_nolegend_nn(18, val_set, model_recall, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_roc_curve(model_loss, test_set, sample=18, device=device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_roc_curve(model_recall, test_set, sample=18, device=device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_roc_curve(model_loss, test_set, device=device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_total_roc_curve(model_recall, test_set, device=device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pr_curve(model_loss, test_set, sample=19, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_evolution(18, test_set, model_loss)\n",
    "show_evolution_nolegend_nn(18, test_set, model_loss, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MORPH_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
